{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The magic of Open AI api with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#install openai if you haven't\n",
    "#pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \"put your secret api key here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "According to the OpenAI docs, GPT-3 models are meant to be used with the text completion endpoint. That’s why we’re using the model text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"Positive\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1674375400,\n",
      "  \"id\": \"cmpl-6bPomDadN0zCP4f3VkejUD6SIovuz\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 2,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 33\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: She is an awesome writer!\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=prompt,\n",
    "              max_tokens=100,\n",
    "              temperature=0\n",
    "            )\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate any code you want\n",
    "\n",
    "Code completion works similarly to text completion, but here we use the Codex model to understand and generate code.\n",
    "\n",
    "The Codex model series is a descendant of the GPT-3 series trained on natural language and billions of lines of code. With Codex, we can turn comments into code, rewrite code for efficiency, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\ndef calculator(num1, num2, operator):\\n    if operator == \\\"+\\\":\\n        return num1 + num2\\n    elif operator == \\\"-\\\":\\n        return num1 - num2\\n    elif operator == \\\"*\\\":\\n        return num1 * num2\\n    elif operator == \\\"/\\\":\\n        return num1 / num2\\n    else:\\n        return \\\"Invalid operator\\\"\\n\\nprint(calculator(10, 20, \\\"+\\\"))\\nprint(calculator(10, 20, \\\"-\\\"))\\nprint(calculator(10, 20, \\\"*\\\"))\\nprint(calculator(10, 20, \\\"/\\\"))\\nprint(calculator(10, 20, \\\"^\\\"))\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1674375401,\n",
      "  \"id\": \"cmpl-6bPonmNktkI3oybzFS2mSa52Lb4zl\",\n",
      "  \"model\": \"code-davinci-002\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 157,\n",
      "    \"prompt_tokens\": 13,\n",
      "    \"total_tokens\": 170\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"\\\"\\\"\\\"\\n Write a function to act as a calculator \\n\\\"\\\"\\\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# a code written as a result of above prompt\n",
    "\n",
    "def calculator(num1, num2, operator): \n",
    "    if operator == \"+\": \n",
    "        return num1 + num2    \n",
    "    elif operator == \"-\":\n",
    "        return num1 - num2    \n",
    "    elif operator == \"*\":        \n",
    "        return num1 * num2    \n",
    "    elif operator == \"/\":        \n",
    "        return num1 / num2    \n",
    "    else:        \n",
    "        return \"Invalid operator\"\n",
    "        \n",
    "        \n",
    "        \n",
    "print(calculator(10, 5, \"+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an image with a single prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-oBPqSoRQFaoVaXEagRkZLl5g/user-SKSVB5m9GXZAtoSIXVik84G2/img-cTttZ9X8kWu4wc0gcKJoZzAo.png?st=2023-01-22T07%3A16%3A59Z&se=2023-01-22T09%3A16%3A59Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-01-22T06%3A53%3A11Z&ske=2023-01-23T06%3A53%3A11Z&sks=b&skv=2021-08-06&sig=D3Qk8S6ZfxfhDXZbVSdq8eClAH8iwcrwf3DMWnQ363A%3D\n"
     ]
    }
   ],
   "source": [
    "response = openai.Image.create(\n",
    "  prompt=\"A tempting image of a fast food\",\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")\n",
    "image_url = response['data'][0]['url']\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
