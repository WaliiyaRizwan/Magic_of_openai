{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The magic of Open AI API with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#install openai if you haven't\n",
    "#pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \"put your secret openAI API key here!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "According to the OpenAI docs, GPT-3 models are meant to be used with the text completion endpoint. That’s why we’re using the model text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"Positive\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1674456164,\n",
      "  \"id\": \"cmpl-6bkpQ2iONiP7x9AYgbxdKS6SK3GqN\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 2,\n",
      "    \"prompt_tokens\": 31,\n",
      "    \"total_tokens\": 33\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: She is an awesome writer!\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=prompt,\n",
    "              max_tokens=100,\n",
    "              temperature=0\n",
    "            )\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate any code you want\n",
    "\n",
    "Code completion works similarly to text completion, but here we use the Codex model to understand and generate code.\n",
    "\n",
    "The Codex model series is a descendant of the GPT-3 series trained on natural language and billions of lines of code. With Codex, we can turn comments into code, rewrite code for efficiency, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\ndef calculator(num1, num2, operator):\\n    if operator == \\\"+\\\":\\n        return num1 + num2\\n    elif operator == \\\"-\\\":\\n        return num1 - num2\\n    elif operator == \\\"*\\\":\\n        return num1 * num2\\n    elif operator == \\\"/\\\":\\n        return num1 / num2\\n    else:\\n        return \\\"Invalid operator\\\"\\n\\nprint(calculator(10, 5, \\\"+\\\"))\\nprint(calculator(10, 5, \\\"-\\\"))\\nprint(calculator(10, 5, \\\"*\\\"))\\nprint(calculator(10, 5, \\\"/\\\"))\\nprint(calculator(10, 5, \\\"^\\\"))\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1674456164,\n",
      "  \"id\": \"cmpl-6bkpQvMh9fWtbH0W88pKfufhIq72R\",\n",
      "  \"model\": \"code-davinci-002\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 157,\n",
      "    \"prompt_tokens\": 13,\n",
      "    \"total_tokens\": 170\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"\\\"\\\"\\\"\\n Write a function to act as a calculator \\n\\\"\\\"\\\"\",\n",
    "  temperature=0,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# a code written as a result of above prompt\n",
    "\n",
    "def calculator(num1, num2, operator): \n",
    "    if operator == \"+\": \n",
    "        return num1 + num2    \n",
    "    elif operator == \"-\":\n",
    "        return num1 - num2    \n",
    "    elif operator == \"*\":        \n",
    "        return num1 * num2    \n",
    "    elif operator == \"/\":        \n",
    "        return num1 / num2    \n",
    "    else:        \n",
    "        return \"Invalid operator\"\n",
    "        \n",
    "        \n",
    "        \n",
    "print(calculator(10, 5, \"+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an image with a single prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-oBPqSoRQFaoVaXEagRkZLl5g/user-SKSVB5m9GXZAtoSIXVik84G2/img-Pn5aPearyUiDfYmUrioFPrjZ.png?st=2023-01-23T05%3A43%3A03Z&se=2023-01-23T07%3A43%3A03Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-01-23T04%3A55%3A04Z&ske=2023-01-24T04%3A55%3A04Z&sks=b&skv=2021-08-06&sig=m5hW1GKlBuZ1orR%2BUDc7MJoZum9iQYOdbIe%2Bbf3qL6M%3D\n"
     ]
    }
   ],
   "source": [
    "response = openai.Image.create(\n",
    "  prompt=\"A tempting image of a fast food\",\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")\n",
    "image_url = response['data'][0]['url']\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" Fast Food Restaurants\\n\\nKFC\\nCategory: Fast Food Restaurants\\n\\nBaskin Robbins\\nCategory: Ice Cream Shops\\n\\nCentaurus\\nCategory: Retail Stores\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1674456346,\n",
      "  \"id\": \"cmpl-6bksMcdEZSukeM7utMj5riqTcIkA3\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 37,\n",
      "    \"prompt_tokens\": 32,\n",
      "    \"total_tokens\": 69\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"The following is a list of companies and the categories they fall into:\\n\\n KFC, Baskin Robins, Centaurus\\n\\nApple\\nCategory:\",\n",
    "  temperature=0,\n",
    "  max_tokens=64,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=\"Create a list of 8 questions for my interview with a Data Engineer:\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \"\\n\\n1. What experience do you have working with data engineering?\\n2. What challenges have you encountered while working with data engineering?\\n3. How do you stay up to date on new technologies and trends related to data engineering?\\n4. What strategies do you use to optimize data engineering processes?\\n5. How do you ensure data accuracy and integrity in your data engineering projects?\\n6. What tools and technologies do you use most often in your data engineering projects?\\n7. How do you ensure data security in your data engineering projects?\\n8. What have been some of your most successful data engineering projects and why?\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1674456185,\n",
      "  \"id\": \"cmpl-6bkplSTZskyFWZEvXvQuYLnkr7I2u\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 129,\n",
      "    \"prompt_tokens\": 14,\n",
      "    \"total_tokens\": 143\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
